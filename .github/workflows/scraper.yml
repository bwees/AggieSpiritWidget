name: Bus Scrape

on:
  schedule:
    - cron: '13 */2 * * *'
  workflow_dispatch:
  
jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          ref: "scraper"

      - name: Use Node.js
        uses: actions/setup-node@v3
        with:
          node-version: 20.x

      - name: Install dependencies
        run: npm install

      - name: Scrape
        run: npm start

      - name: Git Config
        run: |
          # setup the username and email. I tend to use 'GitHub Actions Bot' with no email by default
          git config user.name "GitHub Actions Bot"
          git config user.email "<>"

      - name: commit
        run: |
          git add data.json
          if ! git diff-index --quiet HEAD; then
            git commit -m "New Scrape Data"
            git push origin scraper
          fi
          
      - name: deploy-gist
        uses: exuanbo/actions-deploy-gist@v1
        with:
          token: ${{ secrets.GIST_TOKEN }}
          gist_id: 4e75c40adb4806b4db688ddb550a727f
          file_path: data.json
          file_type: text

  ping-success:
    runs-on: ubuntu-latest
    needs: [scrape]
    steps:
      - run: curl -m 10 --retry 5 ${{ secrets.HEALTHCHECKS_URL }}
  ping-failure:
    runs-on: ubuntu-latest
    if: ${{ failure() }}
    needs: [scrape]
    steps:
      - run: curl -m 10 --retry 5 ${{ secrets.HEALTHCHECKS_URL }}/fail
